{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DepthAnythingV2(\n",
      "  (pretrained): DinoVisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0-23): 24 x NestedTensorBlock(\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MemEffAttention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "    (head): Identity()\n",
      "  )\n",
      "  (depth_head): DPTHead(\n",
      "    (projects): ModuleList(\n",
      "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2-3): 2 x Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (resize_layers): ModuleList(\n",
      "      (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (2): Identity()\n",
      "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (scratch): Module(\n",
      "      (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (refinenet1): FeatureFusionBlock(\n",
      "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (resConfUnit1): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (resConfUnit2): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (refinenet2): FeatureFusionBlock(\n",
      "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (resConfUnit1): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (resConfUnit2): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (refinenet3): FeatureFusionBlock(\n",
      "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (resConfUnit1): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (resConfUnit2): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (refinenet4): FeatureFusionBlock(\n",
      "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (resConfUnit1): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (resConfUnit2): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (output_conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (output_conv2): Sequential(\n",
      "        (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import sys, os\n",
    "depth_anything_path = \"/home/harry7557558/GitHub/external/Depth-Anything-V2/\"\n",
    "sys.path += [depth_anything_path]\n",
    "current_directory = os.getcwd()\n",
    "os.chdir(depth_anything_path)\n",
    "\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "\n",
    "model_configs = {\n",
    "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "}\n",
    "\n",
    "encoder = 'vitl' # or 'vits', 'vitb', 'vitg'\n",
    "\n",
    "model = DepthAnythingV2(**model_configs[encoder])\n",
    "model.load_state_dict(torch.load(f'checkpoints/depth_anything_v2_{encoder}.pth', map_location='cpu'))\n",
    "model = model.to(device).eval()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (1080, 1920)\n",
      "606.5338740008883 ms\n",
      "(3, 1920, 1080) (1920, 1080)\n",
      "0.0 660.4945068359375\n",
      "272.32489013671875 213.77529907226562\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/pride_float/sun_morning_20_16500/images/00160.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/pride_float/mon_evening_5/images/00460.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/solar_clock/10/images/00100.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/utias/20/images/01660.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/coffee/12/images/00516.jpg\"\n",
    "img = \"/media/harry7557558/New Volume/sfm_test/monument/20/images/01220.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/bouquet/10/images/00340.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/mosque/8/images/01248.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/ndravaw/25/images/02000.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/ndravaw/25/images/04900.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/ndravaw2/20/images/04680.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/pit_241203/15/images/00165.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/DinoManTest_JPG_Ori/images/000093.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/chris_yip/20/images/00720.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/2t7/10/images/02430.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/engschool/5/images/00055.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/sfm_test/sydney/imgs/180.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/a2rl_gate/r3w1d1_4/images/00072.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/a2rl_gate/r3w1d3_1/images/00560.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/a2rl_gate/r3w1d3_1/undistorted/00560.jpg\"\n",
    "# img = \"/media/harry7557558/New Volume/a2rl_gate/r3w2d1_6/undistorted/00150.jpg\"\n",
    "\n",
    "img = Image.open(img)\n",
    "\n",
    "from PIL import ExifTags\n",
    "for orientation in ExifTags.TAGS.keys():\n",
    "    if ExifTags.TAGS[orientation]=='Orientation':\n",
    "        break\n",
    "if hasattr(img, '_getexif'):\n",
    "    exif = img._getexif()\n",
    "    if exif is not None and orientation in exif:\n",
    "        print(\"exif orientation:\", exif[orientation])\n",
    "        if exif[orientation] == 3:\n",
    "            img=img.rotate(180, expand=True)\n",
    "        elif exif[orientation] == 6:\n",
    "            img=img.rotate(270, expand=True)\n",
    "        elif exif[orientation] == 8:\n",
    "            img=img.rotate(90, expand=True)\n",
    "\n",
    "x = img.convert(\"RGB\")\n",
    "if False:\n",
    "    scale = 1024/(x.width*x.height)**0.5\n",
    "    w = int(x.width*scale/14+0.5)*14\n",
    "    h = int(x.height*scale/14+0.5)*14\n",
    "    x = x.resize((w, h), Image.LANCZOS)\n",
    "\n",
    "print(\"Image size:\", x.size)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "from time import perf_counter\n",
    "with torch.no_grad():\n",
    "    time0 = perf_counter()\n",
    "    \n",
    "    y = model.infer_image(x)\n",
    "\n",
    "    time1 = perf_counter()\n",
    "    print(1000*(time1-time0), 'ms')\n",
    "\n",
    "x = np.transpose(x, (2, 0, 1)).astype(np.float32) / 255.0\n",
    "print(x.shape, y.shape)\n",
    "print(y.min().item(), y.max().item())\n",
    "print(np.median(y).item(), y.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073600,)\n"
     ]
    }
   ],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "def write_ply(rgb_array, depth_array, file_path):\n",
    "    h, w = depth_array.shape\n",
    "    num_points = w * h\n",
    "\n",
    "    # Flatten arrays\n",
    "    depth_flat = depth_array.flatten()\n",
    "    rgb_flat = rgb_array.reshape((3, -1)).T\n",
    "\n",
    "    # Create vertex data\n",
    "    vertex = np.zeros(num_points, dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4'), \n",
    "                                         ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')])\n",
    "    vertex['x'] = np.tile(np.arange(w), h) / (w*h)**0.5\n",
    "    vertex['y'] = w - np.repeat(np.arange(h), w) / (w*h)**0.5\n",
    "    # vertex['z'] = depth_flat / (2.5*np.std(depth_flat))\n",
    "    # depth_flat = 1.0 / np.clip(depth_flat+0.005, 0.1, np.inf)\n",
    "    vertex['z'] = depth_flat / (3.0*np.mean(depth_flat))\n",
    "    rgb = (np.clip(rgb_flat,0,1)*255+0.5).astype(np.uint8)\n",
    "    vertex['red'] = rgb[:, 0]\n",
    "    vertex['green'] = rgb[:, 1]\n",
    "    vertex['blue'] = rgb[:, 2]\n",
    "\n",
    "    faces = []\n",
    "    depth = vertex['z']\n",
    "    print(depth.shape)\n",
    "    for y in range(h - 1):\n",
    "        for x in range(w - 1):\n",
    "            i00 = y * w + x\n",
    "            i10 = i00 + 1\n",
    "            i01 = (y + 1) * w + x\n",
    "            i11 = i01 + 1\n",
    "            gx = depth[i01]+depth[i11]-depth[i00]-depth[i10]\n",
    "            gy = depth[i10]+depth[i11]-depth[i00]-depth[i01]\n",
    "            if max(depth[i00], depth[i10], depth[i01], depth[i11]) < 1e-4:\n",
    "                continue\n",
    "            if np.hypot(gx, gy) < 20 / (w*h)**0.5:\n",
    "                faces.append(([i00, i10, i11, i01], 0))\n",
    "\n",
    "    faces = np.array(faces,\n",
    "                     dtype=[('vertex_indices', 'i4', (4,)), ('i', 'u1')])\n",
    "\n",
    "    # Create PlyElements\n",
    "    vertex_element = PlyElement.describe(vertex, 'vertex')\n",
    "    face_element = PlyElement.describe(faces, 'face')\n",
    "\n",
    "    # Write to PLY file\n",
    "    ply_data = PlyData([vertex_element, face_element])\n",
    "    ply_data.write(file_path)\n",
    "\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "scale = 512/(x.shape[1]*x.shape[2])**0.5\n",
    "# x = zoom(x, (1, scale, scale))\n",
    "# y = zoom(y, (scale, scale))\n",
    "write_ply(x, y, \"depth_mesh.ply\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
