{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimize L1 loss between closest points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2158\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "import rosbag\n",
    "import rospy\n",
    "\n",
    "bag = rosbag.Bag(\"/home/harry7557558/fast_lio_ws/bag/utias/2024-02-21-13-06-52.bag\")\n",
    "\n",
    "messages = {}\n",
    "for topic, msg, msg_t in bag.read_messages():\n",
    "    if topic not in messages:\n",
    "        messages[topic] = []\n",
    "    messages[topic].append(msg)\n",
    "\n",
    "livox_imu = messages['/livox/imu']\n",
    "livox_lidar = messages['/livox/lidar']\n",
    "\n",
    "bag.close()\n",
    "\n",
    "print(len(livox_imu))\n",
    "print(len(livox_lidar))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate IMU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "angular_velocities = np.array([[msg.angular_velocity.x, msg.angular_velocity.y, msg.angular_velocity.z] for msg in livox_imu])\n",
    "linear_accelerations = 9.81 * np.array([[msg.linear_acceleration.x, msg.linear_acceleration.y, msg.linear_acceleration.z] for msg in livox_imu])\n",
    "\n",
    "# Extract timestamps from IMU messages\n",
    "timestamps_raw = np.array([msg.header.stamp.to_sec() for msg in livox_imu])\n",
    "timestamps = timestamps_raw - timestamps_raw[0]\n",
    "\n",
    "# Create cubic spline interpolations for angular velocity and linear acceleration\n",
    "angular_interp = CubicSpline(timestamps, angular_velocities, axis=0)\n",
    "linear_interp = CubicSpline(timestamps, linear_accelerations, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "import point_cloud_utils as pcu\n",
    "\n",
    "\n",
    "def downsample_point_cloud(pc):\n",
    "\n",
    "    # H = np.dot(pc.T, pc) / pc.shape[0]\n",
    "    # U, S, Vt = np.linalg.svd(H)\n",
    "    # print(S**0.5)\n",
    "\n",
    "    bbox_size = np.amax(pc, 0) - np.amin(pc, 0)\n",
    "    size = np.prod(bbox_size)**(1/3)\n",
    "\n",
    "    sizeof_voxel = bbox_size / (8*size)\n",
    "\n",
    "    return pcu.downsample_point_cloud_on_voxel_grid(sizeof_voxel, pc)\n",
    "\n",
    "\n",
    "def write_point_cloud(points, filename):\n",
    "    vertex = np.array([(x, y, z) for x, y, z in points], dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4')])\n",
    "    vertex_element = PlyElement.describe(vertex, 'vertex')\n",
    "    PlyData([vertex_element], text=False).write(filename)\n",
    "\n",
    "\n",
    "def get_cloud_time(lidar_msg):\n",
    "    points = sorted(lidar_msg.points, key=lambda _: _.offset_time)\n",
    "    time_start = lidar_msg.header.stamp.to_sec()\n",
    "    # points = [p for p in points if timestamps_raw[0]<=time_start+1e-9*p.offset_time<=timestamps_raw[-1]]\n",
    "    times = 1e-9 * np.array([p.offset_time for p in points])\n",
    "    return time_start + times - timestamps_raw[0]\n",
    "\n",
    "\n",
    "def get_cloud(lidar_msg, id=-1):\n",
    "    points = sorted(lidar_msg.points, key=lambda _: _.offset_time)\n",
    "    time_start = lidar_msg.header.stamp.to_sec()\n",
    "    # points = [p for p in points if timestamps_raw[0]<=time_start+1e-9*p.offset_time<=timestamps_raw[-1]]\n",
    "    points = np.array([(p.x, p.y, p.z) for p in points])\n",
    "    # print(times.shape)\n",
    "    # print(points.shape)\n",
    "    points_downsampled = downsample_point_cloud(points)\n",
    "    # print(points_downsampled.shape)\n",
    "    if id >= 0:\n",
    "        write_point_cloud(points, \"{:04d}-raw.ply\".format(id))\n",
    "        write_point_cloud(points_downsampled, \"{:04d}-downsampled.ply\".format(id))\n",
    "    return points_downsampled\n",
    "\n",
    "pcl1 = get_cloud(livox_lidar[0], 0)\n",
    "pcl1_times = get_cloud_time(livox_lidar[0])\n",
    "pcl2 = get_cloud(livox_lidar[40], 40)\n",
    "pcl2_times = get_cloud_time(livox_lidar[40])\n",
    "pcl3 = get_cloud(livox_lidar[100], 100)\n",
    "pcl3_times = get_cloud_time(livox_lidar[100])\n",
    "\n",
    "# print(livox_imu[0], 0)\n",
    "# print(livox_imu[0], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point cloud matching robust to outliers, minimize sum of L1 losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4x4 affine matrix version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success True nit 29 nfev 39\n",
      "0.2572471029998269 secs\n"
     ]
    }
   ],
   "source": [
    "def decode_T(T):\n",
    "    T = T.reshape((4, 4))\n",
    "    U, S, Vt = np.linalg.svd(T[:3, :3])\n",
    "    R = np.dot(U, Vt)\n",
    "    t = T.T[3, :3]\n",
    "    return R, t\n",
    "\n",
    "def decode_T_jacobian(T):\n",
    "    epsilon = 1e-6\n",
    "    R, t = decode_T(T)\n",
    "    num_rows_R, num_cols_R = R.shape\n",
    "    num_rows_t, = t.shape\n",
    "    num_dims_T = len(T)\n",
    "    jacobian_R = np.zeros((num_rows_R, num_cols_R, num_dims_T))\n",
    "    jacobian_t = np.zeros((num_rows_t, num_dims_T))\n",
    "    for i in range(num_dims_T):\n",
    "        delta_T = np.zeros_like(T)\n",
    "        delta_T[i] = epsilon\n",
    "        R_plus, t_plus = decode_T(T + delta_T)\n",
    "        R_minus, t_minus = decode_T(T - delta_T)\n",
    "        jacobian_R[:, :, i] = (R_plus - R_minus) / (2 * epsilon)\n",
    "        jacobian_t[:, i] = (t_plus - t_minus) / (2 * epsilon)\n",
    "    return jacobian_R, jacobian_t\n",
    "\n",
    "\n",
    "def minl1_affine(pc1, pc2, T_guess=np.identity(4)):\n",
    "    T = np.array(T_guess)\n",
    "\n",
    "    kdtree_pc1 = KDTree(pc1)\n",
    "\n",
    "    def fun(T):\n",
    "        R, t = decode_T(T)\n",
    "        dRdt, dtdT = decode_T_jacobian(T)\n",
    "        pc2_transformed = np.dot(pc2, R.T) + t\n",
    "        g_pc2_transformed = np.dot(pc2, dRdt) + dtdT\n",
    "        distances, indices = kdtree_pc1.query(pc2_transformed)\n",
    "        g_distances = np.einsum('nij,ni->nj', g_pc2_transformed, pc2_transformed-pc1[indices]) / \\\n",
    "                (distances.reshape((len(distances), 1)) + 1e-8)\n",
    "        cost = np.mean(distances)\n",
    "        g_cost = np.mean(g_distances, axis=0)\n",
    "        # print(cost)\n",
    "        return cost, g_cost\n",
    "    \n",
    "    # print(scipy.optimize.check_grad(lambda _: fun(_)[0], lambda _: fun(_)[1], T.reshape((-1,))))\n",
    "\n",
    "    res = scipy.optimize.minimize(fun, T.reshape((-1,)), jac=True)\n",
    "    print('success', res.success, 'nit', res.nit, 'nfev', res.nfev)\n",
    "    R, t = decode_T(res.x)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t\n",
    "    pc2_transformed = np.concatenate([pc2, np.ones((len(pc2), 1))], axis=1)\n",
    "    pc2_transformed = np.dot(T, pc2_transformed.T).T[:, :3]\n",
    "    return pc2_transformed, T\n",
    "\n",
    "\n",
    "from time import perf_counter\n",
    "t0 = perf_counter()\n",
    "pc2_transformed, T = minl1_affine(pcl1, pcl2)\n",
    "t1 = perf_counter()\n",
    "print(t1-t0, \"secs\")\n",
    "\n",
    "write_point_cloud(pc2_transformed, \"minl1_affine.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so3 exponential map + translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success True nit 24 nfev 35\n",
      "0.13971671300168964 secs\n"
     ]
    }
   ],
   "source": [
    "def decode_so3t(T):\n",
    "    phi = T[:3]\n",
    "    t = T[3:6]\n",
    "    theta = np.linalg.norm(phi)\n",
    "    R = np.eye(3)\n",
    "    if theta != 0.0:\n",
    "        n = phi / theta\n",
    "        nnT = np.outer(n, n)\n",
    "        n_star = np.array([[0.0, -n[2], n[1]], [n[2], 0.0, -n[0]], [-n[1], n[0], 0.0]])\n",
    "        R = np.cos(theta) * R + \\\n",
    "            (1.0-np.cos(theta)) * nnT + \\\n",
    "            np.sin(theta) * n_star\n",
    "    assert np.linalg.norm(R@R.T-np.eye(3)) < 1e-12\n",
    "    return R, t\n",
    "\n",
    "\n",
    "def minl1_so3t(pc1, pc2, T_guess=np.zeros(6)):\n",
    "    T = np.array(T_guess)\n",
    "\n",
    "    kdtree_pc1 = KDTree(pc1)\n",
    "\n",
    "    def fun(T):\n",
    "        R, t = decode_so3t(T)\n",
    "        Rp = np.dot(pc2, R.T)\n",
    "        pc2_transformed = Rp + t\n",
    "        g_pc2_transformed = np.zeros((*Rp.shape, len(T)), dtype=Rp.dtype)\n",
    "        g_pc2_transformed[:, 0, 1] = Rp[:, 2]\n",
    "        g_pc2_transformed[:, 0, 2] = -Rp[:, 1]\n",
    "        g_pc2_transformed[:, 1, 0] = -Rp[:, 2]\n",
    "        g_pc2_transformed[:, 1, 2] = Rp[:, 0]\n",
    "        g_pc2_transformed[:, 2, 0] = Rp[:, 1]\n",
    "        g_pc2_transformed[:, 2, 1] = -Rp[:, 0]\n",
    "        g_pc2_transformed[:, 0, 3] = 1.0\n",
    "        g_pc2_transformed[:, 1, 4] = 1.0\n",
    "        g_pc2_transformed[:, 2, 5] = 1.0\n",
    "        distances, indices = kdtree_pc1.query(pc2_transformed)\n",
    "        g_distances = np.einsum('nij,ni->nj', g_pc2_transformed, pc2_transformed-pc1[indices]) / \\\n",
    "                (distances.reshape((len(distances), 1)) + 1e-8)\n",
    "        cost = np.mean(distances)\n",
    "        g_cost = np.mean(g_distances, axis=0)\n",
    "        # print(cost)\n",
    "        return cost, g_cost\n",
    "\n",
    "    # print(scipy.optimize.check_grad(lambda _: fun(_)[0], lambda _: fun(_)[1], T))\n",
    "    # assert False\n",
    "\n",
    "    res = scipy.optimize.minimize(fun, T, jac=True)\n",
    "    print('success', res.success, 'nit', res.nit, 'nfev', res.nfev)\n",
    "    R, t = decode_so3t(res.x)\n",
    "    pc2_transformed = np.dot(pc2, R.T) + t\n",
    "    return pc2_transformed, res.x\n",
    "\n",
    "\n",
    "from time import perf_counter\n",
    "t0 = perf_counter()\n",
    "pc2_transformed, T = minl1_so3t(pcl1, pcl2)\n",
    "t1 = perf_counter()\n",
    "print(t1-t0, \"secs\")\n",
    "\n",
    "write_point_cloud(pc2_transformed, \"minl1_so3t.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se3 exponential map, naive gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success True nit 25 nfev 39\n",
      "0.16239492000022437 secs\n"
     ]
    }
   ],
   "source": [
    "def decode_se3(T):\n",
    "    rho = T[0:3]\n",
    "    phi = T[3:6]\n",
    "    theta = max(np.linalg.norm(phi), 1e-12)\n",
    "    n = phi / theta\n",
    "    nnT = np.outer(n, n)\n",
    "    n_star = np.array([[0.0, -n[2], n[1]], [n[2], 0.0, -n[0]], [-n[1], n[0], 0.0]])\n",
    "    C = np.cos(theta) * np.eye(3) + \\\n",
    "        (1.0-np.cos(theta)) * nnT + \\\n",
    "        np.sin(theta) * n_star\n",
    "    J = np.sin(theta)/theta * np.eye(3) + \\\n",
    "        (1.0-np.sin(theta)/theta) * nnT + \\\n",
    "        (1.0-np.cos(theta))/theta * n_star\n",
    "    assert np.linalg.norm(C@C.T-np.eye(3)) < 1e-12\n",
    "    # gamma = 2.0*(1.0-np.cos(theta))/theta**2\n",
    "    # assert np.linalg.norm(J@J.T-(gamma*np.eye(3)+(1.0-gamma)*nnT)) < 1e-10\n",
    "    dJdtheta = (theta*np.cos(theta)-np.sin(theta))/theta**2 * (np.eye(3)-nnT) + \\\n",
    "        (theta*np.sin(theta)+np.cos(theta)-1)/theta**2 * n_star\n",
    "    dnnTdn = np.array([\n",
    "        [[2*n[0], 0, 0], [n[1], n[0], 0], [n[2], 0, n[0]]],\n",
    "        [[n[1], n[0], 0], [0, 2*n[1], 0], [0, n[2], n[1]]],\n",
    "        [[n[2], 0, n[0]], [0, n[2], n[1]], [0, 0, 2*n[2]]]\n",
    "    ])\n",
    "    dnsdn = np.array([\n",
    "        [[0, 0, 0], [0, 0, -1], [0, 1, 0]],\n",
    "        [[0, 0, 1], [0, 0, 0], [-1, 0, 0]],\n",
    "        [[0, -1, 0], [1, 0, 0], [0, 0, 0]]\n",
    "    ], dtype=n.dtype)\n",
    "    dJdn = (1.0-np.sin(theta)/theta) * dnnTdn + \\\n",
    "        (1.0-np.cos(theta))/theta * dnsdn\n",
    "    dJdphi = np.tensordot(dJdtheta, n, axes=0) + \\\n",
    "        np.matmul(dJdn, (np.eye(3)-nnT)/theta)\n",
    "    dvdphi = (dJdphi*rho.reshape(1,len(rho),1)).sum(axis=1)\n",
    "    return C, J, J@rho, dvdphi\n",
    "\n",
    "\n",
    "def minl1_se3_naive(pc1, pc2, T_guess=np.zeros(6)):\n",
    "    T = np.array(T_guess)\n",
    "\n",
    "    kdtree_pc1 = KDTree(pc1)\n",
    "\n",
    "    def fun(T):\n",
    "        C, J, r, dvdphi = decode_se3(T)\n",
    "        Cv = np.dot(pc2, C.T)\n",
    "        pc2_transformed = Cv + r\n",
    "        g_pc2_transformed = np.zeros((*pc2.shape, len(T)), dtype=pc2.dtype)\n",
    "        for i in range(3):\n",
    "            g_pc2_transformed[:,0,3+i] = Cv[:,2]*J[1][i]-Cv[:,1]*J[2][i]\n",
    "            g_pc2_transformed[:,1,3+i] = Cv[:,0]*J[2][i]-Cv[:,2]*J[0][i]\n",
    "            g_pc2_transformed[:,2,3+i] = Cv[:,1]*J[0][i]-Cv[:,0]*J[1][i]\n",
    "        g_pc2_transformed[:,:,3:] += dvdphi\n",
    "        g_pc2_transformed[:,:,:3] = J\n",
    "        distances, indices = kdtree_pc1.query(pc2_transformed)\n",
    "        g_distances = np.einsum('nij,ni->nj', g_pc2_transformed, pc2_transformed-pc1[indices]) / \\\n",
    "                (distances.reshape((len(distances), 1)) + 1e-8)\n",
    "        cost = np.mean(distances)\n",
    "        g_cost = np.mean(g_distances, axis=0)\n",
    "        # print(cost)\n",
    "        return cost, g_cost\n",
    "\n",
    "    # print(scipy.optimize.check_grad(lambda _: fun(_)[0], lambda _: fun(_)[1], T))\n",
    "    # assert False\n",
    "\n",
    "    res = scipy.optimize.minimize(fun, T, jac=True)\n",
    "    print('success', res.success, 'nit', res.nit, 'nfev', res.nfev)\n",
    "    R, _1, t, _2 = decode_se3(res.x)\n",
    "    pc2_transformed = np.dot(pc2, R.T) + t\n",
    "    return pc2_transformed, res.x\n",
    "\n",
    "\n",
    "from time import perf_counter\n",
    "t0 = perf_counter()\n",
    "# T = np.array([-1, 2, -3, 0.2, 0.1, 0.3])\n",
    "T = np.array([0, 0, 0, 0, 0, 0])\n",
    "pc2_transformed, T = minl1_se3_naive(pcl1, pcl2, T)\n",
    "t1 = perf_counter()\n",
    "print(t1-t0, \"secs\")\n",
    "\n",
    "write_point_cloud(pc2_transformed, \"minl1_se3_naive.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try it on a bunch of point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success True nit 19 nfev 23\n",
      "success True nit 16 nfev 26\n",
      "success True nit 37 nfev 47\n",
      "success True nit 28 nfev 38\n",
      "success True nit 43 nfev 55\n",
      "success True nit 42 nfev 55\n",
      "success True nit 49 nfev 68\n",
      "success True nit 57 nfev 77\n",
      "(52150, 3)\n"
     ]
    }
   ],
   "source": [
    "pcls = [\n",
    "    get_cloud(livox_lidar[0], -1)\n",
    "]\n",
    "all_pcl = pcls[-1]\n",
    "T = np.zeros(6)\n",
    "minl1 = minl1_so3t\n",
    "for i in range(1, 80, 10):\n",
    "    pcl = get_cloud(livox_lidar[i])\n",
    "    # pcl_transformed, T = minl1(pcls[-1], pcl, T)\n",
    "    pcl_transformed, T = minl1(all_pcl, pcl, T)\n",
    "    pcls.append(pcl_transformed)\n",
    "    all_pcl = np.concatenate((all_pcl, pcl_transformed))\n",
    "print(all_pcl.shape)\n",
    "write_point_cloud(all_pcl, \"minl1.ply\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
