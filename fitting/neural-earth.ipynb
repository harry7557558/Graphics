{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Train a neural network to fit an earth texture on a unit sphere and export GLSL code.","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn, tensor\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import transforms, ToTensor\nimport torchvision.utils as vutils\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-18T16:38:52.303012Z","iopub.execute_input":"2022-08-18T16:38:52.303655Z","iopub.status.idle":"2022-08-18T16:38:52.311222Z","shell.execute_reply.started":"2022-08-18T16:38:52.303616Z","shell.execute_reply":"2022-08-18T16:38:52.309004Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Load the earth texture. Average two UV images.","metadata":{}},{"cell_type":"code","source":"import requests\n\ndef load_image(url):\n    req = requests.get(url, headers={\n        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36',\n        'accept': '*/*',\n        'accept-language': 'en-US,en;q=0.5',\n        'cache-control': 'no-cache',\n        'pragma': 'no-cache'\n    })\n    print(req.status_code)\n    with open(\"temp\", 'wb') as fp:\n        fp.write(req.content)\n    image = Image.open(\"temp\").convert(\"RGB\")\n    image = np.array(image.resize((512, 256))) / 255.0\n    return image.astype(np.float32)\n\nearth_img_1 = load_image(\"https://www.solarsystemscope.com/textures/download/2k_earth_daymap.jpg\")\nearth_img_2 = load_image(\"https://eoimages.gsfc.nasa.gov/images/imagerecords/73000/73801/world.topo.bathy.200409.3x5400x2700.jpg\")\nearth_img = 0.5 * (earth_img_1 + earth_img_2)\nplt.imshow(earth_img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T16:38:52.315672Z","iopub.execute_input":"2022-08-18T16:38:52.316209Z","iopub.status.idle":"2022-08-18T16:38:55.297640Z","shell.execute_reply.started":"2022-08-18T16:38:52.316181Z","shell.execute_reply":"2022-08-18T16:38:55.296666Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"class PixelDataSet(Dataset):\n    def __init__(self, image):\n        self.shape = image.shape[:2]\n        self.image = image\n        # generate points on an unit sphere\n        h, w = self.shape\n        u = 2.0*np.pi*((np.arange(w)+0.5)/w-0.5)\n        v = -np.pi*((np.arange(h)+0.5)/h-0.5)\n        x = np.outer(np.cos(v), np.cos(u))\n        y = np.outer(np.cos(v), np.sin(u))\n        z = np.outer(np.sin(v), np.ones(len(u)))\n        w = np.outer(np.cos(v), np.ones(len(u)))  # arial element\n        coords = np.einsum(\"nab->abn\", [x, y, z])\n        #w = np.einsum(\"nab->abn\", [w, 0.25*w, 0.25*w])  # yuv\n        w = np.einsum(\"nab->abn\", [w, w, w])  # rgb\n        self.coords = coords.astype(np.float32)\n        self.weights = w.astype(np.float32)\n        #print(self.shape, self.image.shape, self.coords.shape, self.weights.shape)\n\n    def __len__(self):\n        return np.prod(self.image.shape[:2])\n\n    def __getitem__(self, i):\n        i, j = i // self.shape[1], i % self.shape[1]\n        return [self.image[i][j],\n                self.coords[i][j],\n                self.weights[i][j]]\n\nfor pixel, coord, weight in DataLoader(\n    PixelDataSet(earth_img),\n    batch_size=16,\n    shuffle=True\n):\n    print(pixel.dtype, coord.dtype, weight.dtype)\n    print(pixel.shape, coord.shape, weight.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-08-18T16:38:55.299720Z","iopub.execute_input":"2022-08-18T16:38:55.300471Z","iopub.status.idle":"2022-08-18T16:38:55.327998Z","shell.execute_reply.started":"2022-08-18T16:38:55.300431Z","shell.execute_reply":"2022-08-18T16:38:55.326828Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"Define model.\n\nHidden layers: sine activation\n\nLast hidden layer: sigmoid activation\n\nOutput layer: sigmoid activation","metadata":{}},{"cell_type":"code","source":"class Siren(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, x):\n        return torch.sin(x)\n\nclass Model(nn.Module):\n    def __init__(self, hidden_layers):\n        super().__init__()\n        layers = [3] + hidden_layers + [3]\n        sequence = []\n        for i in range(len(layers)-2):\n            sequence += [\n                nn.Linear(layers[i], layers[i+1]),\n                nn.Sigmoid() if i==len(layers)-3 else Siren()\n            ]\n        sequence += [\n            nn.Linear(layers[-2], layers[-1]),\n            nn.Sigmoid()\n        ]\n        self.main = nn.Sequential(*sequence)\n    \n    def forward(self, x):\n        return self.main(x)\n\n\nmodel = Model([12, 12, 12, 8]).to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T16:38:55.329629Z","iopub.execute_input":"2022-08-18T16:38:55.330300Z","iopub.status.idle":"2022-08-18T16:38:55.341871Z","shell.execute_reply.started":"2022-08-18T16:38:55.330261Z","shell.execute_reply":"2022-08-18T16:38:55.340789Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"Loss function - YUV","metadata":{}},{"cell_type":"code","source":"YUV = tensor([\n    [0.299, 0.587, 0.114],\n    [-0.14713, -0.28886, 0.436],\n    [0.615, -0.51499, -0.10001]\n]).to(device)\n\ndef lossFun(output, expected, weight):\n    #output = torch.einsum(\"ab,cb->ca\", (YUV, output))\n    #expected = torch.einsum(\"ab,cb->ca\", (YUV, expected))\n    diff = expected - output\n    return torch.sum(weight*diff**2)/torch.sum(weight)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T16:38:55.345221Z","iopub.execute_input":"2022-08-18T16:38:55.346168Z","iopub.status.idle":"2022-08-18T16:38:55.353174Z","shell.execute_reply.started":"2022-08-18T16:38:55.346118Z","shell.execute_reply":"2022-08-18T16:38:55.352289Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"Training - gradient descent","metadata":{}},{"cell_type":"code","source":"dataloader = list(DataLoader(\n    PixelDataSet(earth_img),\n    batch_size=64,\n    shuffle=True\n))\n\noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=0.005, betas=(0.9, 0.999))\n\nprint(\"ADAM\")\ncount = 0\nfor epoch in range(1, 10+1):\n    print(\"Epoch\", epoch)\n    for pixel, coord, weight in dataloader:\n        pixel = pixel.to(device)\n        coord = coord.to(device)\n        weight = weight.to(device)\n        optimizer.zero_grad()\n        output = model(coord)\n        loss = lossFun(output, pixel, weight)\n        loss.backward()\n        optimizer.step()\n        \n        count += 1\n        if count % 1024 == 0:\n            print(\"Iteration {} - loss = {}\".format(count, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2022-08-18T16:38:55.355072Z","iopub.execute_input":"2022-08-18T16:38:55.355782Z","iopub.status.idle":"2022-08-18T16:39:36.931868Z","shell.execute_reply.started":"2022-08-18T16:38:55.355704Z","shell.execute_reply":"2022-08-18T16:39:36.930896Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"Train - BFGS","metadata":{}},{"cell_type":"code","source":"dataloader = list(DataLoader(\n    PixelDataSet(earth_img),\n    batch_size=int(np.prod(earth_img.shape[:2])),\n    shuffle=False\n))\n\noptimizer = torch.optim.LBFGS(\n    model.parameters(),\n    max_iter=20)\n\nprint(\"L-BFGS\")\n\ncount = 0\ncount_t = 0\niteration = 0\ndef closure():\n    global count, count_t\n    optimizer.zero_grad()\n    for pixel, coord, weight in dataloader:\n        pixel = pixel.to(device)\n        coord = coord.to(device)\n        weight = weight.to(device)\n        output = model(coord)\n        loss = lossFun(output, pixel, weight)\n        loss.backward()\n    count += 1\n    count_t += 1\n    if count_t == 1 and iteration % 10 == 0:\n        print(\"Evaluation {} - loss = {}\".format(count, loss.item()))\n    return loss\n\nwhile iteration < 100:\n    count_t = 0\n    iteration += 1\n    optimizer.step(closure)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T16:40:21.548879Z","iopub.execute_input":"2022-08-18T16:40:21.549899Z","iopub.status.idle":"2022-08-18T16:40:53.726963Z","shell.execute_reply.started":"2022-08-18T16:40:21.549851Z","shell.execute_reply":"2022-08-18T16:40:53.725964Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"Test - generate an image","metadata":{}},{"cell_type":"code","source":"h, w = (128, 256)\nu = 2.0*np.pi*((np.arange(w)+0.5)/w-0.5)\nv = -np.pi*((np.arange(h)+0.5)/h-0.5)\nx = np.outer(np.cos(v), np.cos(u))\ny = np.outer(np.cos(v), np.sin(u))\nz = np.outer(np.sin(v), np.ones(len(u)))\ncoords = np.einsum(\"kab->abk\", [x, y, z])\ncoords = torch.tensor(coords, dtype=torch.float).to(device)\ncolors = model(coords).detach().cpu().numpy()\nplt.imshow(colors)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T16:41:00.323515Z","iopub.execute_input":"2022-08-18T16:41:00.323950Z","iopub.status.idle":"2022-08-18T16:41:00.542670Z","shell.execute_reply.started":"2022-08-18T16:41:00.323919Z","shell.execute_reply":"2022-08-18T16:41:00.541782Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"Export GLSL code","metadata":{}},{"cell_type":"code","source":"def num2str(x, d=3):\n    s = \"{:.{prec}f}\".format(x, prec=d)\n    while s[0] == '0':\n        s = s[1:]\n    while s[0] == '-' and s[1] == '0':\n        s = '-' + s[2:]\n    while len(s) > 0 and s[-1] in ['0', '.']:\n        s = s[0:len(s)-1]\n    if s in ['', '-']:\n        s = '0'\n    return s\n\ndef vec2str(v, d=3):\n    return f'vec{len(v)}(' + ','.join([num2str(x, d=d) for x in v]) + ')'\n\ndef mat2str(m, d=3):\n    v = m.flatten()\n    return 'mat4(' + ','.join([num2str(x, d=d) for x in v]) + ')'\n\ndigits = 2\n\ndef print_input_layer(l: int, weight, bias):\n    assert weight.shape[1] == 3\n    for i in range(0, len(bias), 4):\n        w = weight[i:i+4].T\n        b = bias[i:i+4]\n        s = '+'.join([\n            vec2str(w[0], digits)+'*p.x',\n            vec2str(w[1], digits)+'*p.y',\n            vec2str(w[2], digits)+'*p.z',\n            vec2str(b, digits)\n        ])\n        print(f\"  vec4 v{l}{i//4} = sin({s});\")\n\ndef print_hidden_layer(l: int, weight, bias, activate: str):\n    for i in range(0, len(bias), 4):\n        w = weight[i:i+4].T\n        b = bias[i:i+4]\n        terms = []\n        for j in range(0, len(w), 4):\n            s = mat2str(w[j:j+4], digits)\n            s += f\"*v{l-1}{j//4}\"\n            terms.append(s)\n        terms.append(vec2str(b, digits))\n        s = '+'.join(terms)\n        print(f\"  vec4 v{l}{i//4} = {activate}({s});\")\n\ndef print_output_layer(l: int, weight, bias):\n    assert weight.shape[0] == 3 and len(bias) == 3\n    for i in range(3):\n        w = weight[i]\n        b = bias[i]\n        terms = []\n        for j in range(0, len(w), 4):\n            s = vec2str(w[j:j+4], digits)\n            s = f\"dot({s},v{l-1}{j//4})\"\n            terms.append(s)\n        terms.append(num2str(b, digits))\n        s = '+'.join(terms)\n        print(f\"  float v{l}{i} = sigmoid({s});\")\n\nlayers = []\n\nfor layer in model.main:\n    if hasattr(layer, 'weight'):\n        assert hasattr(layer, 'bias')\n        weight = layer.weight.detach().cpu().numpy()\n        bias = layer.bias.detach().cpu().numpy()\n        layers.append((weight, bias))\n\nfor i in range(len(layers)):\n    weight, bias = layers[i]\n    assert weight.shape[0] == len(bias)\n    assert len(bias) == 3 or len(bias) % 4 == 0\n    print('  //', weight.shape, bias.shape)\n    if weight.shape[1] == 3:\n        print_input_layer(i, weight, bias)\n    elif weight.shape[0] == 3:\n        print_output_layer(i, weight, bias)\n    else:\n        activate = 'sigmoid' if i==len(layers)-2 else 'sin'\n        print_hidden_layer(i, weight, bias, activate)\nprint(f\"  return vec3(v{i}0, v{i}1, v{i}2);\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-18T16:41:42.572660Z","iopub.execute_input":"2022-08-18T16:41:42.573208Z","iopub.status.idle":"2022-08-18T16:41:42.596493Z","shell.execute_reply.started":"2022-08-18T16:41:42.573172Z","shell.execute_reply":"2022-08-18T16:41:42.595322Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}