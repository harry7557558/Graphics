// Neural network regression

// Input: (x, y, z, 1)
// Hidden layer 1: LN1 neurons + bias, sine activation
// Hidden layer 2: LN2 neurons + bias, sine activation
// Hidden layer 3: LN3 neurons + bias, tanh activation
// Output: scalar, sigmoid activation

#pragma GCC optimize "Ofast"
#pragma GCC optimize "unroll-loops"
#pragma GCC target "sse,sse2,sse3,sse4,abm,avx,mmx,popcnt"


#include "bunny_optimizer.h"

#include <chrono>


// model

#define L1N 16
#define L2N 16
#define L3N 12
#define L1WN (L1N*4)
#define L2WN (L2N*(L1N+1))
#define L3WN (L3N*(L2N+1))
#define L4WN (L3N+1)
#define WN (L1WN+L2WN+L3WN+L4WN)

void model(const double* w, vec3 x, double* y, double* y_grad) {
    // input
    double f0[4] = { x.x, x.y, x.z, 1.0 };
    // layer 1
    double f1[L1N + 1], g1[L1N];
    for (int i = 0; i < L1N; i++) {
        double s = 0.0;
        for (int j = 0; j <= 3; j++)
            s += w[i + j * L1N] * f0[j];
        f1[i] = sin(s), g1[i] = cos(s);
    }
    f1[L1N] = 1.0;
    // layer 2
    double f2[L2N + 1], g2[L2N];
    for (int i = 0; i < L2N; i++) {
        double s = 0.0;
        for (int j = 0; j <= L1N; j++)
            s += w[L1WN + i + j * L2N] * f1[j];
        f2[i] = sin(s), g2[i] = cos(s);
    }
    f2[L2N] = 1.0;
    // layer 3
    double f3[L3N + 1], g3[L3N];
    for (int i = 0; i < L3N; i++) {
        double s = 0.0;
        for (int j = 0; j <= L2N; j++)
            s += w[L1WN + L2WN + i + j * L3N] * f2[j];
        // f3[i] = sin(s), g3[i] = cos(s);
        f3[i] = tanh(s), g3[i] = 1.0 / (cosh(s) * cosh(s));
    }
    f3[L3N] = 1.0;
    // output
    double f4, g4;
    {
        double s = 0.0, g = 1.0;
        for (int j = 0; j <= L3N; j++) {
            s += w[L1WN + L2WN + L3WN + j] * f3[j];
        }
        // f4 = s, g4 = 1.0;
        f4 = 1.0 / (1.0 + exp(-s)), g4 = f4 * (1.0 - f4);
    }
    *y = f4;
    for (int j = 0; j <= L3N; j++)
        y_grad[L1WN + L2WN + L3WN + j] = f3[j] * g4;
    // backprop layer 3
    double b3[L3N];
    for (int i = 0; i < L3N; i++) {
        for (int j = 0; j <= L2N; j++) {
            b3[i] = w[L1WN + L2WN + L3WN + i] * g4;
            y_grad[L1WN + L2WN + i + j * L3N] = b3[i] * g3[i] * f2[j];
        }
    }
    // backprop layer 2
    double b2[L2N];
    for (int i = 0; i < L2N; i++) {
        b2[i] = 0.0;
        for (int j = 0; j < L3N; j++)
            b2[i] += b3[j] * g3[j] * w[L1WN + L2WN + j + i * L3N];
        for (int j = 0; j <= L1N; j++)
            y_grad[L1WN + i + j * L2N] = b2[i] * g2[i] * f1[j];
    }
    // backprop layer 1
    for (int i = 0; i < L1N; i++) {
        double b1i = 0.0;
        for (int j = 0; j < L2N; j++)
            b1i += b2[j] * g2[j] * w[L1WN + j + i * L2N];
        for (int j = 0; j <= 3; j++)
            y_grad[i + j * L1N] = b1i * g1[i] * f0[j];
    }
}


// Loss function
void lossMse(int ndata, const double* w, const vec3* x, const double* y, double* v, double* v_grad) {
    *v = 0.0;
    for (int i = 0; i < WN; i++) v_grad[i] = 0.0;
    double f;
    double* f_grad = new double[WN];
    for (int i = 0; i < ndata; i++) {
        model(w, x[i], &f, f_grad);
        double d = f - y[i];
        *v += d * d;
        double g = 2.0 * d;
        for (int j = 0; j < WN; j++) v_grad[j] += f_grad[j] * g;
    }
    *v /= double(ndata);
    for (int j = 0; j < WN; j++) v_grad[j] /= double(ndata);
    delete f_grad;
}

// evaluate the loss function with verbose
void evaluateWeights(int ndata, const double* w, vec3* x, double* y) {
    for (int i = 0; i < WN; i++) printf("%.3lf,", w[i]); printf("\n");
    double loss;
    double* grad = new double[WN];
    lossMse(ndata, w, x, y, &loss, grad);
    double gradnorm = 0.0;
    for (int i = 0; i < WN; i++) gradnorm += grad[i] * grad[i];
    gradnorm = sqrt(gradnorm);
    printf("loss=%lf grad=%lf\n", loss, gradnorm);
}


// Training
//  - Run `minimizeAdam` 2-4 times until the final loss increase
//  - Run `minimizeLossBfgs` once

// 8, 8, 8 - 185 weights, 0.0020
// double w[WN] = { -0.295,-4.750,-0.464,2.482,1.051,2.211,1.638,0.584,2.435,-0.297,1.526,0.173,0.456,2.289,-0.878,0.147,1.818,1.079,-0.731,0.146,2.093,0.526,0.131,-1.768,-1.289,0.747,1.033,-0.507,0.304,-1.793,0.680,-1.304,1.660,2.556,-0.061,0.019,0.641,0.156,0.899,0.825,1.377,-0.048,0.403,-0.098,-0.086,0.127,0.164,0.069,-1.584,0.154,2.460,0.088,0.736,0.278,-0.582,-1.557,1.082,-1.058,1.725,1.421,0.307,2.129,0.850,0.684,-0.360,-0.453,2.298,-0.740,-0.319,-0.644,0.522,0.873,1.224,0.138,-0.471,-0.127,-0.081,-0.668,0.392,0.426,1.312,1.768,-1.240,-2.530,-0.645,1.061,-1.417,-1.013,-0.401,-0.426,-1.279,3.870,1.166,-0.917,0.857,-2.333,-0.707,-2.685,0.730,1.400,-2.244,1.637,-1.667,-2.537,-0.720,1.486,0.184,-0.953,-1.185,-0.436,4.281,-0.026,3.703,-0.787,-4.097,0.670,0.960,4.811,-3.614,0.616,1.775,0.527,-2.419,1.259,1.291,2.644,-0.585,-1.179,2.582,-2.249,-2.533,-0.576,0.149,1.887,1.220,-0.803,5.934,1.274,-2.359,4.359,0.123,-0.301,-3.652,0.102,-0.947,1.885,1.858,-1.232,-0.389,-1.900,2.206,3.851,-1.092,4.011,-1.160,6.281,5.346,1.605,-12.770,-5.895,3.171,2.335,-4.066,1.307,2.069,4.410,9.417,-4.410,-8.823,5.652,6.484,-2.806,-1.504,-9.177,-1.087,0.246,1.810,-1.648,1.838,-1.104,3.780,1.752,0.162,-2.618,-1.972 };

// 12, 10, 8 - 275 weights, 0.0015
// double w[WN] = { 2.970,0.176,2.012,-2.973,-1.994,1.037,-3.610,1.499,0.071,1.881,-0.028,-0.175,0.287,2.253,-1.102,0.119,0.857,-2.838,-1.268,1.692,0.134,2.298,-0.045,-1.991,-1.575,-0.302,0.483,-0.099,-2.384,-2.355,-2.677,-1.438,-1.440,1.430,-0.024,-1.814,-0.498,-0.971,1.924,-0.572,-1.654,-2.303,-1.013,1.151,-0.907,-1.196,0.032,-0.368,-0.274,-0.093,0.661,-0.052,0.470,-0.127,-2.564,0.818,0.931,-0.330,-0.020,1.465,-2.056,-0.180,0.293,0.480,0.244,-2.291,-1.281,0.556,0.121,0.120,3.448,0.353,-0.486,-0.756,0.647,-0.051,-0.310,-1.301,-0.038,0.731,1.467,0.547,0.697,-1.800,-1.598,-0.355,-0.136,0.552,-0.445,-1.267,1.150,-0.651,0.748,-0.593,0.190,0.212,-0.670,-0.392,-0.575,-0.286,-1.290,-0.481,0.810,0.486,0.605,-0.245,0.280,1.009,-0.114,-0.515,0.141,-0.742,-0.151,0.467,0.342,0.198,0.588,-0.317,0.456,0.720,-0.850,2.188,-0.667,-2.664,-0.615,0.314,0.556,-0.364,-3.252,1.157,1.028,-1.340,1.522,-3.128,-0.216,-0.341,0.604,-0.934,-0.003,-0.697,-2.221,0.691,0.462,-0.303,-1.003,-0.048,-0.361,1.033,0.006,0.001,0.143,0.084,0.033,0.063,0.020,-0.062,-0.076,-0.016,-0.315,-2.125,-0.289,-2.455,0.120,0.656,1.567,-2.043,1.335,0.201,-1.945,-2.405,-2.395,0.128,-2.050,0.899,0.079,4.080,1.215,-2.316,-2.811,-1.961,-0.420,1.320,6.897,1.186,1.866,-3.621,-0.974,-0.022,0.946,3.439,-1.200,-0.625,-0.126,-2.989,0.524,-0.659,-0.614,0.248,-2.762,-0.588,-0.085,2.494,-1.895,0.600,1.269,-1.477,1.359,1.102,1.278,-1.652,-2.025,2.916,1.970,-2.428,-4.313,3.585,1.551,3.418,-2.797,-0.270,1.861,0.621,-1.059,-0.430,0.170,3.444,-3.944,0.731,2.507,-0.423,2.931,-1.083,1.043,1.811,1.790,-0.337,0.092,2.147,-0.253,1.681,0.903,-0.706,-0.805,0.924,1.182,-2.126,1.838,0.258,0.419,6.540,-1.011,3.721,1.586,-4.298,1.926,-1.057,2.591,5.600,-2.186,0.361,0.498,-1.664,-12.588,4.022,-0.092,9.800,1.982,3.148,2.479,-1.962,-2.933,-1.003,-1.077,-0.599,-6.096 };

// 12, 12, 12 - 373 weights, 0.0012
// double w[WN] = { -3.415,-0.047,0.170,0.002,0.003,-0.052,-1.739,3.228,-0.003,-1.021,2.820,0.062,0.475,3.206,-0.881,1.409,-0.019,-3.676,0.004,0.517,0.017,0.503,-0.253,-2.006,-1.015,0.946,3.438,1.357,0.012,-3.647,1.685,-0.864,-0.005,-2.294,-0.149,0.506,0.031,-1.057,3.010,0.368,-0.006,-2.020,1.582,0.063,0.005,-1.831,-1.657,-0.052,0.065,-0.180,-0.171,-1.414,0.063,-0.001,-0.197,-0.137,0.168,-0.264,-1.694,0.980,-1.011,0.775,-0.813,0.562,-1.337,-0.333,1.089,1.642,-1.121,-0.239,0.604,2.021,0.269,0.567,0.056,-0.491,-0.098,0.879,0.274,-0.317,1.125,1.153,0.216,-0.252,0.346,-1.445,-2.670,1.991,-0.319,1.513,-0.574,0.372,2.418,-1.534,0.129,0.155,-0.023,0.003,0.009,-0.018,0.012,-0.010,-0.001,0.004,0.003,-0.019,0.016,-0.046,-0.103,0.175,-0.658,-0.448,-0.457,-0.638,-0.268,0.212,0.184,-0.392,0.507,-0.645,0.369,-0.936,0.728,0.561,0.833,0.470,1.438,0.614,0.040,0.091,0.025,0.301,0.570,0.121,-0.284,-0.927,0.750,-0.094,-0.462,-0.455,0.645,-0.475,1.243,-0.246,0.026,-0.003,0.008,0.013,-0.014,-0.002,0.011,-0.000,-0.009,0.018,-0.011,0.053,-0.290,1.673,-1.188,-0.525,-1.156,-0.288,-1.649,-0.059,-0.494,-0.850,-1.542,-0.176,-1.823,2.339,-0.133,-0.222,-0.376,-0.057,0.076,-0.990,0.964,-1.025,-0.158,-1.680,-0.289,1.490,0.969,2.404,0.002,1.350,-0.344,0.466,0.492,-1.414,0.195,-0.139,3.317,-0.021,1.449,0.503,1.738,-0.235,-2.736,-1.151,1.662,2.140,-1.313,0.028,-0.638,-1.756,-3.198,-2.484,-5.810,0.275,-0.376,2.058,1.413,-2.665,2.631,0.924,-1.888,-0.503,-2.202,-0.587,0.485,0.943,1.507,0.855,0.560,0.258,-1.746,0.395,6.418,0.582,-0.122,0.190,-0.771,-0.189,-3.709,-0.805,-2.284,3.682,-0.352,-2.143,-0.824,-0.959,-0.390,-0.836,2.581,0.661,1.591,1.743,3.210,2.028,0.109,2.641,2.383,-2.677,0.910,-3.220,8.590,0.385,-1.586,1.875,-0.308,-1.028,0.810,-1.245,3.428,0.570,-0.045,3.572,-2.151,-2.177,-4.491,-0.535,0.887,-1.316,2.928,2.665,-8.329,0.220,-2.630,0.921,-3.462,1.895,3.859,1.626,4.593,1.526,-0.780,4.510,1.974,-0.736,-2.045,-1.624,5.189,0.885,-0.344,1.438,2.626,2.034,-2.673,1.949,2.031,2.513,-2.914,0.786,0.974,-1.424,-1.465,-0.247,1.280,0.475,-1.026,1.479,-3.588,-0.894,-0.115,3.726,-3.044,2.599,1.306,0.876,1.427,0.946,2.461,1.517,-0.375,0.195,1.842,0.084,1.481,-2.488,0.002,-0.044,0.435,2.747,3.532,0.706,-0.641,-0.070,-0.907,-0.339,-0.836,1.912,-0.190,-0.384,-2.473,-0.079,-1.189,-2.530,1.420,0.883,7.201,0.467,-7.626,-0.605,-3.400,0.708,2.624,-8.736,8.852,0.089,1.643,2.776,-1.699,-0.970,0.246,-2.318,1.934,-3.267,0.395,1.715,-2.244,-0.413,-1.400 };

// 16, 16, 12 - 553 weights, 0.0008
double w[WN] = { 0.846,0.025,0.460,0.029,-2.808,-0.032,-2.835,0.839,-0.170,0.021,2.067,1.965,2.032,1.479,0.631,-1.051,0.623,0.015,-0.515,-0.013,-0.089,0.001,-0.177,-2.949,-1.962,-0.007,2.925,-1.200,0.299,-2.242,-2.200,-3.754,1.864,-0.011,2.650,0.002,-0.328,-0.012,0.475,-0.101,-0.427,-0.004,0.450,1.437,-1.448,-2.042,-2.725,0.723,0.910,-0.018,-0.479,-0.011,1.018,0.023,-0.224,1.699,-0.268,-0.003,-1.164,1.101,-1.428,0.275,-2.190,0.299,-0.764,-1.647,1.466,-0.728,-2.212,-1.186,-0.281,-0.339,-2.671,-1.375,-1.149,-0.128,-0.146,0.587,0.342,-0.000,-0.032,0.026,0.063,0.016,-0.024,-0.014,-0.133,-0.003,-0.086,-0.084,0.042,-0.261,-0.019,-0.055,-0.012,0.023,0.530,0.391,0.137,1.083,0.840,-1.376,-1.075,-0.410,2.313,-1.434,1.857,0.932,-1.399,1.683,0.878,0.567,0.001,0.053,0.012,-0.017,0.030,-0.029,0.033,-0.032,-0.020,-0.018,-0.009,-0.080,0.019,-0.116,-0.020,0.009,0.105,0.981,1.349,0.179,-0.822,1.111,1.267,-1.513,-0.460,-1.380,1.608,-0.660,-0.087,0.472,0.671,-0.323,-0.022,-0.047,0.051,0.052,-0.071,-0.013,-0.048,0.047,0.024,0.004,0.048,0.028,-0.045,0.057,0.012,-0.040,-0.320,-0.290,1.475,-2.597,0.128,-1.097,-0.299,0.692,-1.142,0.299,-0.630,-2.398,0.179,1.128,0.753,0.902,0.492,0.096,-1.361,0.576,0.439,0.313,0.875,-0.948,1.593,0.618,0.449,1.641,0.753,0.797,-0.511,-0.878,1.739,-0.572,2.333,-0.873,0.674,-0.530,-1.571,0.123,-0.196,1.370,-0.396,1.932,-0.004,-0.567,0.780,-0.412,-0.012,0.028,0.015,0.019,0.008,-0.037,-0.023,-0.020,-0.025,-0.025,0.011,-0.073,-0.010,-0.105,-0.017,-0.009,-0.375,0.068,0.066,-0.355,-0.075,-1.088,-0.411,0.166,2.245,-0.407,0.508,-0.162,0.810,0.147,1.516,0.874,-1.994,-1.009,-0.708,0.721,0.478,-0.610,0.281,0.497,-0.933,-0.225,-0.560,1.104,0.211,-2.613,0.616,-0.286,2.003,1.701,0.059,-0.977,-0.935,0.519,1.799,0.045,0.342,0.788,1.214,-2.941,-0.842,-1.839,0.166,0.099,-0.014,0.406,-1.480,1.677,0.203,1.064,-1.856,-0.197,-2.308,1.765,0.673,0.090,-0.601,-0.519,-0.643,-0.343,-0.243,0.629,-0.006,0.933,1.005,0.100,-0.684,0.150,0.070,1.980,0.151,-0.168,-0.866,1.560,1.071,0.782,-0.631,0.247,1.230,-0.540,-0.772,-0.624,-0.895,-0.407,-0.187,0.734,0.828,-1.765,-0.122,-0.026,-0.580,-0.017,-0.176,-2.126,-0.771,1.106,2.487,2.105,-1.660,-2.729,3.494,-0.188,1.752,1.679,-0.580,1.694,-1.961,-2.436,-0.602,-0.968,-1.361,3.404,-3.634,0.849,2.607,-1.853,1.012,-0.989,0.752,-0.056,-0.999,0.485,2.446,-8.052,-0.440,-4.302,-2.695,-0.513,-1.221,-3.519,0.731,5.547,0.437,-0.156,-0.033,-3.299,-1.907,0.205,0.201,-1.356,1.060,-0.102,0.751,-0.963,-1.483,-0.533,-1.070,1.838,0.370,-0.847,-1.415,1.503,-2.282,0.008,0.179,0.089,0.128,1.072,1.219,-1.538,-0.741,-0.333,-2.443,3.509,-0.289,-0.407,-2.429,-0.926,-1.734,-1.819,0.865,2.145,0.275,1.464,-0.964,1.915,-0.296,0.269,2.772,-1.243,-0.111,-0.886,-0.739,6.021,-0.302,0.582,-1.666,1.850,-0.103,-0.475,-1.176,-0.636,2.439,0.869,3.625,-2.252,0.716,2.213,3.601,-4.206,0.293,-1.107,8.725,7.707,0.652,0.445,-0.063,-0.424,1.512,-0.230,1.930,-2.160,-0.457,-0.100,-0.340,-0.315,0.142,-0.471,-0.792,-1.916,0.369,0.635,-2.897,3.354,-1.471,-0.540,-1.487,-1.526,-0.874,1.161,0.159,-1.286,1.527,-1.340,-1.099,0.406,-2.172,-1.868,1.457,1.122,0.786,-0.368,-0.722,-0.214,2.054,0.540,0.433,-1.633,0.307,-0.096,-1.639,1.125,1.252,1.941,1.240,-2.894,2.329,-1.173,-1.423,2.364,-1.091,1.148,-3.026,1.977,0.974,-0.350,0.368,-0.028,0.244,0.090,0.658,-1.272,1.552,-0.310,0.300,1.040,0.884,0.847,0.938,-4.951,-0.247,-0.005,0.511,-3.645,-1.145,-0.171,0.567,0.976,3.018,2.315,1.032,0.606,4.793,0.884,-1.944,-0.398,-2.056,3.207,-3.861,-2.041,0.748,-0.471,-1.828,-2.552,2.239,-4.629,-7.999,9.829,-2.874,-6.682,-12.877,-16.578,2.243,2.429,-0.997,0.209,1.228,1.035,1.164,1.003,-1.862,4.024,1.672,-3.677,-3.557 };

void fitTooth() {

    // weights
#if 0
    _IDUM = 0u;
    for (int i = 0; i < WN; i++)
        w[i] = -1.0 + 2.0 * randf();
#endif
    printf("%d weights\n", WN);

    // data
    std::vector<vec3> x;
    std::vector<double> y;
    int ndata = load_tooth(x, y);

    // check the correctness of gradient
    printf("checkgrad=%lf\n", checkGrad(WN, [=](const double* w, double* val, double* grad) {
        // model(w, x[0], val, grad);
        lossMse(400, w, &x[ndata / 2], &y[ndata / 2], val, grad);
        }, w, 1e-6, false));
    // return;

    evaluateWeights(ndata, w, &x[0], &y[0]);

    // comment one of the following lines
    minimizeAdam(WN, ndata, lossMse, w, &x[0], &y[0], 500, 0.01, 0.9, 0.999, 50, 1e-5);
    minimizeLossBfgs(WN, ndata, lossMse, w, &x[0], &y[0], 20, 1e-5);

    evaluateWeights(ndata, w, &x[0], &y[0]);
}

// timing
int main(int argc, char* argv[]) {

    auto t0 = std::chrono::high_resolution_clock::now();

    fitTooth();

    auto t1 = std::chrono::high_resolution_clock::now();
    double dt = std::chrono::duration<double>(t1 - t0).count();
    printf("%.2lf secs elapsed.\n", dt);

    return 0;
}
